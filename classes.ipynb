{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "from pandas import Series, DataFrame\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "import pylab\n",
    "import missingno as msno\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import shapiro\n",
    "import scipy\n",
    "from numbers import Number\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.stats.api as sms\n",
    "import numpy as np \n",
    "from sklearn import tree\n",
    "from scipy.stats import levene\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "from scipy.cluster.hierarchy import linkage\n",
    "\n",
    "from scipy.stats import f_oneway\n",
    "from scipy.stats import pearsonr\n",
    "import statsmodels.formula.api as smf\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.preprocessing import scale, MinMaxScaler\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from scipy.cluster.hierarchy import linkage\n",
    "from patsy import dmatrices\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import seaborn as sns\n",
    "from skompiler import skompile\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split, cross_val_score,GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import model_selection\n",
    "import pandas as pd\n",
    "from catboost import CatBoostRegressor\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "from warnings import filterwarnings\n",
    "from sklearn.neural_network import MLPRegressor,MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "filterwarnings(\"ignore\")\n",
    "\n",
    "class Information():\n",
    "    def __init__(self,data):\n",
    "        self.data=data\n",
    "        \n",
    "    def Describe(self):\n",
    "        print(self.data.describe().T)\n",
    "        \n",
    "    def Info(self):\n",
    "        print(self.data.info())\n",
    "        \n",
    "    def Head(self):\n",
    "        print(self.data.head())\n",
    "              \n",
    "    def ColumnTypes(self):\n",
    "        print(self.data.dtypes)\n",
    "              \n",
    "    def NullValues(self):\n",
    "        print(self.data.isnull().values.any())\n",
    "        print(self.data.isnull().sum())\n",
    "              \n",
    "    def Count(self):\n",
    "        print(self.data.count())\n",
    "              \n",
    "    def Num_data(self):\n",
    "        print(self.data.select_dtypes(include=['float64','int64']))\n",
    "              \n",
    "    def Cat_data(self):\n",
    "        print(self.data.select_dtypes(include=[\"object\"]))\n",
    "              \n",
    "    def nuniques(self):\n",
    "        unique = self.data.nunique()\n",
    "        return unique\n",
    "        \n",
    "              \n",
    "class Visualization():\n",
    "    def __init__(self,data):\n",
    "        self.data = data\n",
    "        \n",
    "    def barplot(self,x,y,z = None):\n",
    "        bar = sns.barplot(x = x, y = y, hue = z, data = self.data);\n",
    "        return bar\n",
    "    def frekans(self, x):\n",
    "        fre = self.data[str(x)].value_counts().plot.barh()\n",
    "        return fre\n",
    "    \n",
    "    def catplot(self, x, y, z = None):\n",
    "        cat = sns.catplot(x = x, y = y, hue = z, data = self.data);\n",
    "        return cat\n",
    "    \n",
    "    def histogram(self,x, y = None):\n",
    "        hist = sns.FacetGrid(self.data,hue = y,height = 5).map(sns.kdeplot, x, shade= True).add_legend();\n",
    "        return hist\n",
    "    \n",
    "    def boxplot(self,x, y = None, z = None):\n",
    "        box = sns.boxplot(x = x, y = y, hue = z, data=self.data);\n",
    "        return box\n",
    "    \n",
    "    def crosstab(self, col1, col2, normalize=None):\n",
    "        return pd.crosstab(index=self.data[str(col1)], columns=self.data[str(col2)])\n",
    "    \n",
    "    def violin(self, x , y , z = None):\n",
    "        vio = sns.catplot(x= x, y = y, hue = z, kind = \"violin\", data = self.data);\n",
    "        return vio\n",
    "    \n",
    "    def distplot(self, col1):\n",
    "        dist = sns.distplot(self.data[str(col1)], bins = 10, kde = False);\n",
    "        return dist\n",
    "    \n",
    "    def jointplot(self,x,y):\n",
    "        joint = sns.jointplot(x = x, y = y ,data = self.data, kind=\"reg\");\n",
    "        return joint\n",
    "    \n",
    "    def scatter(self, x, y, z = None, s = None):\n",
    "        sca = sns.scatterplot(x = x, y = y, hue=z, size = s, data = self.data);\n",
    "        return sca\n",
    "    \n",
    "    def lmplot(self, x, y, z = None, c = None, r = None):\n",
    "        lm = sns.lmplot(x = x, y = y, hue = z, col = c, row = r, data = self.data);\n",
    "        return lm\n",
    "    \n",
    "    def pairplot(self, x = None):\n",
    "        pair = sns.pairplot(self.data, kind = \"reg\", hue = x);\n",
    "        return pair\n",
    "    \n",
    "    def heatmap(self):\n",
    "        heat = sns.heatmap(self.data, annot = True, fmt = \"d\");\n",
    "        return heat\n",
    "    \n",
    "    def corr(self):      \n",
    "        fig,ax = plt.subplots(figsize=(7, 7))\n",
    "        sns.heatmap(self.data.corr(), ax=ax, annot=True, linewidths=0.05, fmt= '.2f',cmap=\"magma\")\n",
    "        plt.show()\n",
    "    \n",
    "    def dendogram(self):\n",
    "        dendogram = msno.dendrogram(self.data)\n",
    "        return dendogram\n",
    "    \n",
    "    def probplot(self, col):\n",
    "        prob = stats.probplot(self.data[col],dist='norm',plot=pylab)\n",
    "        pylab.show()\n",
    "    \n",
    "    def lineplot(self, x, y, z = None, s = None):\n",
    "        lin = sns.lineplot(x = x, y = y, hue = z, style = s, markers = True,  dashes = False, data = self.data);\n",
    "        return lin\n",
    "    \n",
    "    def countplot(self, column):\n",
    "        count = sns.countplot(self.data.iloc[:,column], data = self.data, palette = \"Set3\");\n",
    "        return count\n",
    "\n",
    "    def PieChart(self):\n",
    "        pie = plt.pie(self.data, labels = self.data.index, counterclock = False, shadow = True)\n",
    "        return pie \n",
    "        \n",
    "              \n",
    "class PreProcessing:\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        \n",
    "    def dropna(self):\n",
    "        return self.data.dropna()\n",
    "\n",
    "    def Delete_col(self, inplace):\n",
    "        del_col = self.data.dropna(axis=1, inplace=inplace)\n",
    "        return del_col\n",
    "    \n",
    "    def Delete_row(self, inplace):\n",
    "        del_row = self.data.dropna(axis=0, inplace=inplace)\n",
    "        return del_row\n",
    "    \n",
    "    def calc_vif(self):\n",
    "        vif[\"variables\"] = self.data.columns\n",
    "        vif[\"VIF\"] = [variance_inflation_factor(self.data.values, i) for i in range(self.data.shape[1])]\n",
    "        return(vif)\n",
    "\n",
    "    def Dummy(self):\n",
    "        dummy_data = pd.get_dummies(self.data)\n",
    "        return dummy_data\n",
    "    \n",
    "    def normalization(self):\n",
    "        return preprocessing.normalize(self.data)\n",
    "    \n",
    "    def outlier(self):\n",
    "        lower_and_upper = {}\n",
    "        columns = list(self.data.select_dtypes(include=[\"float64\",\"int64\"]))\n",
    "        for col in columns:\n",
    "            q1 = self.data[col].quantile(0.25)\n",
    "            q3 = self.data[col].quantile(0.75)\n",
    "            iqr = 1.5*(q3-q1)\n",
    "    \n",
    "            lower_bound = q1-iqr\n",
    "            upper_bound = q3+iqr\n",
    "    \n",
    "            lower_and_upper[col] = (lower_bound, upper_bound)\n",
    "            self.data.loc[(self.data.loc[:,col]<lower_bound),col]=lower_bound\n",
    "            self.data.loc[(self.data.loc[:,col]>upper_bound),col]=upper_bound\n",
    "         \n",
    "        return self.data\n",
    "\n",
    "    def DropColumn(self, column):\n",
    "        drop =  self.data.drop(column, inplace=True, axis=1)\n",
    "        return drop\n",
    "\n",
    "    def Label_Encoder(self, column):\n",
    "        label_encoder = preprocessing.LabelEncoder()\n",
    "        LE = label_encoder.fit_transform(self.data[column])\n",
    "        return LE\n",
    "    \n",
    "    def standardization(self):\n",
    "        st_data = preprocessing.scale(self.data)\n",
    "        return st_data\n",
    "\n",
    "    \n",
    "              \n",
    "class statistic():\n",
    "    def __init__(self, data):\n",
    "        self.data=data\n",
    "        \n",
    "        \n",
    "    def shapiro(self):\n",
    "        for col in self.data.columns[1:]:\n",
    "            if self.data[col].dtypes != object:\n",
    "                stat, p = shapiro(self.data[col])\n",
    "                print('Shapiro Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "                alpha = 0.05\n",
    "                if p > alpha:\n",
    "                    print(col)\n",
    "                    print('\\033[1m'+ col + '\\033[0m','Örneklem Normal (Gaussian) dağılımdan gelmektedir (fail to Reject) \\n')\n",
    "                else:\n",
    "                    print('\\033[1m'+ col + \":\"+'\\033[0m','Örneklem Normal (Gaussian) dağılımdan gelmemektedir (Reject H0)\\n')\n",
    "        \n",
    "    def chi2(self,col1,col2): \n",
    "        cross=pd.crosstab(index=self.data[col2], columns=self.data[col1])\n",
    "        chi2,p,dof,expected= stats.chi2_contingency(cross)\n",
    "        result=[[\"chi\",chi2],[\"p\",p]]\n",
    "        print(result)\n",
    "        \n",
    "    def spearmanr(self, col_1, col_2):\n",
    "        stats.spearmanr(self.data[col_1],self.data[col_2])\n",
    "        alpha=0.05\n",
    "        if(p>alpha):\n",
    "            print('Statistics=%.3f, p=%.3f' % (stat,p), 'aralarındaki bu ilişki anlamsızdır') \n",
    "        else:\n",
    "            print('Statistics=%.3f, p=%.3f' % (stat,p), 'aralarında bir ilişki vardır ve bu ilişki anlamlıdır')\n",
    "        \n",
    "    def ttest_one(self,column,popmean):\n",
    "        stat, p = self.stats.ttest_one(self.data[column], popmean = popmean)\n",
    "        print(\"Statistics:%3.3f, p=%.3f \" % (stat,p))\n",
    "            \n",
    "    def lev_ttest(self,col1,col2):\n",
    "        x = Series(self.data[col1].iloc[:][data[col2]==1])\n",
    "        y = Series(self.data[col1].iloc[:][data[col2]==0])\n",
    "        print(\"HİPOTEZ:\")\n",
    "        print(\"H0:{}-{}=1 and {}-{} =0 have same distribution\\n\".format(col1,col2,col1,col2))\n",
    "        stat, p=stats.levene(x,y)\n",
    "        print(\"Levene Statistic= {}, p-val={}\".format(stat,p))\n",
    "        if p<0.05:\n",
    "            print(\"H0--> Reject. They have different variance\\n\")\n",
    "        else:\n",
    "            print(\"H0--> Fail to Reject.\")\n",
    "            \n",
    "        if p<0.05:\n",
    "            equal_var=False\n",
    "        else:\n",
    "            equal_var=True\n",
    "        print(\"ttest_two:\")\n",
    "        stat, p=stats.ttest_ind(x,y)\n",
    "        print(\"Statistic= {}, p-val={}\".format(stat,p))\n",
    "        if p<0.05:\n",
    "            print(\"H0--> Reject. They have different mean\\n\")\n",
    "        else:\n",
    "            print(\"H0--> Fail to Reject.\")\n",
    "    \n",
    "    def VIF(self,X):\n",
    "        vif = pd.DataFrame()\n",
    "        vif[\"VIF Factor\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "        vif[\"features\"] = X.columns\n",
    "        print(vif)\n",
    "    \n",
    "    \n",
    "class Model():\n",
    "    def __init__(self):\n",
    "        self.data=data\n",
    "        \n",
    "    def train_test_split(self,y,X):\n",
    "        self.X =X\n",
    "        self.y =y\n",
    "        shuffle = input(\"Please enter shufle: \")\n",
    "        X_train,X_test,y_train,y_test= train_test_split(X,y,test_size=0.20,random_state=42,shuffle=shuffle)\n",
    "        print(\"X_train\",X_train.shape)\n",
    "        print(\"y_train\",y_train.shape)\n",
    "        print(\"X_test\",X_test.shape)\n",
    "        print(\"y_test\",y_test.shape)\n",
    "        return X_train,X_test,y_train,y_test\n",
    "    \n",
    "    def stats_model(self,y,X):\n",
    "        self.X =X\n",
    "        self.y =y\n",
    "        lm = sm.OLS(y,X)\n",
    "        model = lm.fit()\n",
    "        print(model.summary())\n",
    "        \n",
    "    def stats_model_2(self,y,X):\n",
    "        self.X =X\n",
    "        self.y =y\n",
    "        loj = sm.Logit(self.y,self.X)\n",
    "        loj1 = loj.fit()\n",
    "        print(loj1.summary())   \n",
    "        \n",
    "    def Linear_Regresyon(self,X_train=None,X_test=None,y_train=None,y_test=None):\n",
    "        lm=LinearRegression()\n",
    "        lr=lm.fit(X_train,y_train)\n",
    "        return lr\n",
    "        \n",
    "    def Linear_Regression_PCA(self,X_train=None,X_test=None,y_train=None,y_test=None):\n",
    "        pca =PCA()\n",
    "        \n",
    "        X_reduced_train = pca.fit_transform(scale(X_train))\n",
    "        X_reduced_test= pca.fit_transform(scale(X_test))\n",
    "        \n",
    "        print(np.cumsum(np.round(pca.explained_variance_ratio_, decimals=4)*100)[0:50])\n",
    "        \n",
    "        lm = LinearRegression()\n",
    "        pcr_model = lm.fit(X_reduced_train, y_train)\n",
    "        y_pred = pcr_model.predict(X_reduced_test)\n",
    "        print(\"RMSE  :\" , np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "        print(\"r2_score : \" , r2_score(y_test, y_pred))\n",
    "            \n",
    "    def Logisctic_Regression(self,X_train=None,X_test=None,y_train=None,y_test=None):\n",
    "\n",
    "        loj =LogisticRegression(solver = \"liblinear\")\n",
    "        loj_model = loj.fit(X_train, y_train)\n",
    "        print(loj_model)\n",
    "        print(\"----------------------------Train---------------\")\n",
    "        print(accuracy_score(y_train,loj_model.predict(X_train)))\n",
    "        print(confusion_matrix(y_train,loj_model.predict(X_train)))\n",
    "        print(classification_report(y_train,loj_model.predict(X_train)))\n",
    "        print(\"-----------------Test--------------\")\n",
    "        y_pred=loj_model.predict(X_test)\n",
    "        print(accuracy_score(y_test,y_pred))\n",
    "        print(confusion_matrix(y_test,y_pred))\n",
    "        print(classification_report(y_test,y_pred))\n",
    "        \n",
    "        \n",
    "        print(loj_model.predict_proba(X_test)[0:10])\n",
    "        y_probs=loj_model.predict_proba(X_test)\n",
    "        y_probs=y_probs[:,1]\n",
    "        y_pred2=[1 if i>0.4 else 0 for i in y_probs]\n",
    "        print(\"iyileştirme\")\n",
    "        print(confusion_matrix(y_test,y_pred2))\n",
    "        print(classification_report(y_test,y_pred2))\n",
    "        y_probs=loj_model.predict_proba(X_test)\n",
    "        y_probs=y_probs[:,1]\n",
    "        y_pred3=[1 if i>0.2 else 0 for i in y_probs]\n",
    "        \n",
    "        print(\"iyileştirme\")\n",
    "        print(confusion_matrix(y_test,y_pred3))\n",
    "        print(classification_report(y_test,y_pred3))\n",
    "        \n",
    "        print(\"-----------------Test--------------\")\n",
    "        print(cross_val_score(loj_model,X_test,y_test, cv=10).mean())\n",
    "        \n",
    "        print(\"----------------------------Train---------------\")\n",
    "        print(cross_val_score(loj_model,X_train,y_train, cv=10).mean())\n",
    "        \n",
    "        \n",
    "\n",
    "        logit_roc_auc = roc_auc_score(y_test, loj_model.predict(X_test))\n",
    "\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, loj_model.predict_proba(X_test)[:,1])\n",
    "        print(\"-----------------Test--------------\")\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(fpr, tpr, label='AUC (area = %0.2f)' % logit_roc_auc)\n",
    "        plt.plot([0, 1], [0, 1],'r--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Oranı')\n",
    "        plt.ylabel('True Positive Oranı')\n",
    "        plt.title('ROC')\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"----------------------------Train---------------\")\n",
    "        logit_roc_auc=roc_auc_score(y_train,loj_model.predict(X_train))\n",
    "        fpr, tpr, thresholds = roc_curve(y_train, loj_model.predict_proba(X_train)[:,1])\n",
    "        plt.figure()\n",
    "        plt.plot(fpr, tpr, label='AUC (area = %0.2f)' % logit_roc_auc)\n",
    "        plt.plot([0, 1], [0, 1],'r--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.0])\n",
    "        plt.xlabel('False Positive Oranı')\n",
    "        plt.ylabel('True Positive Oranı')\n",
    "        plt.title('ROC')\n",
    "        plt.show()\n",
    "        return loj_model\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def Model_Tuning(self,X_train= None,y_train = None,params= None,model=None):\n",
    "        model_cv = GridSearchCV(model, params, cv=10, n_jobs = -1, verbose = 2)\n",
    "        model_tuned = model_cv.fit(X_train, y_train)\n",
    "        print(\"En iyi parametreler: \" + str(model_tuned.best_params_))\n",
    "        return model_tuned.best_params_\n",
    "        \n",
    "    def NN_Classification(self,X_train=None,X_test=None,y_train=None,y_test=None,best_params=None):\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X_train)\n",
    "        X_train_scaled = scaler.transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        mlpc = MLPClassifier(**best_params)\n",
    "        mlpc.fit(X_train_scaled, y_train)\n",
    "        print(mlpc)\n",
    "        y_pred = mlpc.predict(X_test_scaled)\n",
    "        print(\"------------------Accuracy Score------------------\")\n",
    "        print(accuracy_score(y_test, y_pred))\n",
    "        (\"------------------classification_report------------------\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        return mlpc\n",
    "        \n",
    "        \n",
    "    def CART_Classification(self,X_train=None,X_test=None,y_train=None,y_test=None,best_params=None):\n",
    "        cart = DecisionTreeClassifier(**best_params)\n",
    "        cart_model = cart.fit(X_train, y_train)\n",
    "        print(cart_model)\n",
    "        \n",
    "        fig, axes = plt.subplots(nrows = 1,ncols = 1,figsize = (50,50), dpi=300)\n",
    "\n",
    "        tree.plot_tree(cart_model,\n",
    "           filled = True);\n",
    "\n",
    "        fig.savefig('tree_class.png')\n",
    "        print(skompile(cart_model.predict).to(\"python/code\"))\n",
    "        y_pred = cart_model.predict(X_test)\n",
    "        print(\"------------------Accuracy Score------------------\")\n",
    "        print(accuracy_score(y_test, y_pred))\n",
    "        \n",
    "        print(\"------------------confusion_matrix------------------\")\n",
    "        print(confusion_matrix(y_test,y_pred))\n",
    "        return cart\n",
    "        \n",
    "    def RF_Classification(self,X_train=None,X_test=None,y_train=None,y_test=None,best_params=None):\n",
    "        rf_model = RandomForestClassifier(**best_params).fit(X_train, y_train)\n",
    "        print(rf_model)\n",
    "        y_pred = rf_model.predict(X_test)\n",
    "        print(\"------------------Accuracy Score------------------\")\n",
    "        print(accuracy_score(y_test, y_pred))\n",
    "        print(\"------------------confusion_matrix------------------\")\n",
    "        print(confusion_matrix(y_test,y_pred))\n",
    "        \n",
    "        Importance = pd.DataFrame({\"Importance\": rf_model.feature_importances_*100},\n",
    "                         index = X_train.columns)\n",
    "        Importance.sort_values(by = \"Importance\", \n",
    "                       axis = 0, \n",
    "                       ascending = True).plot(kind =\"barh\", color = \"r\")\n",
    "\n",
    "        plt.xlabel(\"Değişken Önem Düzeyleri\")\n",
    "        return rf_model\n",
    "        \n",
    "    def NN_Regression(self,X_train=None,X_test=None,y_train=None,y_test=None,best_params=None):\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X_train)\n",
    "        X_train_scaled = scaler.transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        mlp_model = MLPRegressor(**best_params).fit(X_train_scaled, y_train)\n",
    "        print(mlp_model)\n",
    "        y_pred = mlp_model.predict(X_test_scaled)\n",
    "        print(\"-----------------------------MSE--------------------\")\n",
    "        print(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "        return mlp_model\n",
    "        \n",
    "    def CART_Regression(self,X_train=None,X_test=None,y_train=None,y_test=None,best_params=None):\n",
    "        cart_model = DecisionTreeRegressor(**best_params)\n",
    "        cart_model.fit(X_train, y_train)\n",
    "        fig, axes = plt.subplots(nrows = 1,ncols = 1,figsize = (50,50), dpi=300)\n",
    "        tree.plot_tree(cart_model,\n",
    "                   filled = True);\n",
    "        fig.savefig('tree_reg.png')\n",
    "        \n",
    "        print(skompile(cart_model.predict).to('python/code'))\n",
    "        y_pred =cart_model.predict(X_test)\n",
    "        print(\"-----------------------------MSE--------------------\")\n",
    "        print(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "        return cart_model\n",
    "        \n",
    "        \n",
    "    def RF_Regression(self,X_train=None,X_test=None,y_train=None,y_test=None,best_params=None):\n",
    "        rf_model = RandomForestRegressor(**best_params)\n",
    "        rf_model.fit(X_train, y_train)\n",
    "        y_pred = rf_model.predict(X_test)\n",
    "        print(\"-----------------------------MSE--------------------\")\n",
    "        print(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "        \n",
    "        Importance = pd.DataFrame({\"Importance\": rf_model.feature_importances_*100},\n",
    "                         index = X_train.columns)\n",
    "        Importance.sort_values(by=\"Importance\", axis=0, ascending=True).plot(kind=\"barh\", color=\"r\")\n",
    "        plt.xlabel(\"Degiskenlerin Onem Duzeyleri\")\n",
    "        plt.show()\n",
    "        return rf_model\n",
    "        \n",
    "    def SVR(self,X_train=None,X_test=None,y_train=None,y_test=None,best_params=None):\n",
    "        svr = SVR(**best_params).fit(X_train, y_train)\n",
    "        print(svr)\n",
    "        y_pred = svr.predict(X_test)\n",
    "        print(\"-----------------------------MSE--------------------\")\n",
    "        print(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "        return svr\n",
    "        \n",
    "    def CatBoostRegressor(self,X_train=None,X_test=None,y_train=None,y_test=None,best_params=None):\n",
    "        catb = CatBoostRegressor(**best_params)\n",
    "        catb_model = catb.fit(X_train, y_train)\n",
    "        print(catb_model)\n",
    "        y_pred = catb_model.predict(X_test)\n",
    "        print(\"-----------------------------MSE--------------------\")\n",
    "        print(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "        return catb_model\n",
    "    \n",
    "    def KNeighborsRegressor(self,X_train=None,X_test=None,y_train=None,y_test=None,best_params=None):\n",
    "        knn_model = KNeighborsRegressor(**best_params).fit(X_train, y_train)\n",
    "        print(knn_model)\n",
    "        print(knn_model.n_neighbors)\n",
    "        print(knn_model.effective_metric_)\n",
    "        y_pred = knn_model.predict(X_test)\n",
    "        print(\"-----------------------------MSE--------------------\")\n",
    "        print(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "        RMSE = [] \n",
    "        RMSE_CV = []\n",
    "        for k in range(10):\n",
    "            k = k+1\n",
    "            knn_model = KNeighborsRegressor(n_neighbors = k).fit(X_train, y_train)\n",
    "            y_pred = knn_model.predict(X_train) \n",
    "            rmse = np.sqrt(mean_squared_error(y_train,y_pred)) \n",
    "            rmse_cv = np.sqrt(-1*cross_val_score(knn_model, X_train, y_train, cv=10, \n",
    "                                         scoring = \"neg_mean_squared_error\").mean())\n",
    "            RMSE.append(rmse) \n",
    "            RMSE_CV.append(rmse_cv)\n",
    "            print(\"k =\" , k , \"için RMSE değeri: \", rmse, \"RMSE_CV değeri: \", rmse_cv )\n",
    "        return knn_model\n",
    "    \n",
    "    def KMEANS(self,X_train=None,X_test=None,y_train=None,y_test=None):\n",
    "        pca = PCA(n_components=4)\n",
    "        X_reduced_train = pca.fit_transform(scale(X_train))\n",
    "        X_reduced_test = pca.fit_transform(scale(X_test))\n",
    "        pca_data = pca.fit_transform(scale(data))\n",
    "        pca_data = pd.DataFrame(pca_data)\n",
    "        print(np.cumsum(np.round(pca.explained_variance_ratio_, decimals = 4) * 100))\n",
    "        n_cluster = input(\"Please enter n_cluster: \")\n",
    "        kmeans = KMeans(n_clusters=n_cluster)\n",
    "        k_fit = kmeans.fit(pca_data)\n",
    "        print(k_fit.cluster_centers_)\n",
    "        print(k_fit.labels_)\n",
    "        visualizer = KElbowVisualizer(kmeans, k=(2,50))\n",
    "        visualizer.fit(pca_data)\n",
    "        visualizer.poof()\n",
    "        n_cluster = input(\"Please enter n_cluster: \")\n",
    "        kmeans = KMeans(n_clusters= n_cluster)\n",
    "        k_fit = kmeans.fit(pca_data)\n",
    "        kumeler = k_fit.labels_\n",
    "        merkezler = k_fit.cluster_centers_\n",
    "        plt.scatter(pca_data.iloc[:,0], pca_data.iloc[:,1], merkezler, c= kumeler,  cmap = \"viridis\")\n",
    "        plt.scatter(merkezler[:,0], merkezler[:,1], c=\"black\", s= 200, alpha = 0.5)\n",
    "        \n",
    "    def NaiveBayes(self,X_train=None,X_test=None,y_train=None,y_test=None):\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(X_train)\n",
    "        X_train_scaled = scaler.transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        nb = MultinomialNB()\n",
    "        nb_model = nb.fit(X_train_scaled, y_train)\n",
    "        print(nb_model)\n",
    "        y_pred = nb_model.predict(X_test_scaled)\n",
    "        print(\"Test başarı oranı\")\n",
    "        print(accuracy_score(y_test, y_pred))\n",
    "        y_pred = nb_model.predict(X_train_scaled)\n",
    "        print(\"Train başarı oranı\")\n",
    "        print(accuracy_score(y_train, y_pred))\n",
    "        \n",
    "    def SVC(self,X_train=None,X_test=None,y_train=None,y_test=None,best_params=None):\n",
    "        svc_model = SVC(**best_params)\n",
    "        svc_model.fit(X_train, y_train)\n",
    "        print(svc_model)\n",
    "        y_pred = svc_model.predict(X_test)\n",
    "        print(\"Test başarı oranı\")\n",
    "        print(accuracy_score(y_test, y_pred))\n",
    "        print(classification_report(y_test,svc_model.predict(X_test)))\n",
    "        y_pred = svc_model.predict(X_train)\n",
    "        print(\"Train başarı oranı\")\n",
    "        print(accuracy_score(y_train, y_pred))\n",
    "        print(classification_report(y_train,svc_model.predict(X_train)))\n",
    "        return svc_model\n",
    "        \n",
    "        \n",
    "    def KNeighborsClassifier(self,X_train=None,X_test=None,y_train=None,y_test=None,best_params=None):\n",
    "        knn = KNeighborsClassifier(**best_params)\n",
    "        knn_model = knn.fit(X_train, y_train)\n",
    "        print(knn_model)\n",
    "        y_pred = knn_model.predict(X_test)\n",
    "        (\"------------------Accuracy Score------------------\")\n",
    "        print(accuracy_score(y_test, y_pred))\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        return knn_model\n",
    "        \n",
    "    def CatBoostClassifier(self,X_train=None,X_test=None,y_train=None,y_test=None,best_params=None):\n",
    "        cat_model = CatBoostClassifier(**best_params).fit(X_train, y_train)\n",
    "        y_pred = cat_model.predict(X_test)\n",
    "        (\"------------------Accuracy Score------------------\")\n",
    "        print(accuracy_score(y_test, y_pred))\n",
    "        (\"------------------classification_report------------------\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        return cat_model\n",
    "        \n",
    "    def GradientBoostingClassifier(self,X_train=None,X_test=None,y_train=None,y_test=None,best_params=None):\n",
    "        gbm_model = GradientBoostingClassifier(**best_params).fit(X_train, y_train)\n",
    "        y_pred = gbm_model.predict(X_test)\n",
    "        (\"------------------Accuracy Score------------------\")\n",
    "        print(accuracy_score(y_test, y_pred))\n",
    "        (\"------------------classification_report------------------\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        return gbm_model\n",
    "    \n",
    "    def Testing(modeller=None,X_test=None,y_test=None):\n",
    "        for model in modeller:\n",
    "            isimler = model.__class__.__name__\n",
    "            y_pred = model.predict(X_test)\n",
    "            dogruluk = accuracy_score(y_test, y_pred)\n",
    "            print(\"-\"*28)\n",
    "            print(isimler + \":\" )\n",
    "            print(\"Accuracy: {:.4%}\".format(dogruluk))\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
